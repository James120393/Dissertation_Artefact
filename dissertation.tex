%% LaTeX template for BSc Computing for Games final year project dissertations
%% by Edward Powley
%% Games Academy, Falmouth University, UK

%% Based on:
%% bare_jrnl.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% see http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE
%% journal paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************


\documentclass[journal]{IEEEtran}

\usepackage{graphicx}
% to embed the file `myreferences.bib` in your `.tex` file
% Insert additional usepackage commands here
\usepackage{color}
\usepackage{listings}
%\usepackage{courier} %caused problems for me

\lstloadlanguages{% Check Dokumentation for further languages ...
	C,
	C++,
	csh,
	Java
}

\definecolor{red}{rgb}{0.6,0,0} % for strings
\definecolor{blue}{rgb}{0,0,0.6}
\definecolor{green}{rgb}{0,0.8,0}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\lstset{
	language=csh,
	basicstyle=\footnotesize\ttfamily, 
	numbers=left, 
	numberstyle=\tiny, 
	numbersep=5pt, 
	tabsize=2, 
	extendedchars=true, 
	breaklines=true, 
	frame=b,
	stringstyle=\color{blue}\ttfamily, 
	showspaces=false, 
	showtabs=true, 
	xleftmargin=17pt,
	framexleftmargin=17pt,
	framexrightmargin=5pt,
	framexbottommargin=4pt,
	commentstyle=\color{green},
	morecomment=[l]{//}, %use comment-line-style!
	morecomment=[s]{/*}{*/}, %for multiline comments
	showstringspaces=false, 
	morekeywords={  abstract, event, new, struct,
		as, explicit, null, switch,
		base, extern, object, this,
		bool, false, operator, throw,
		break, finally, out, true,
		byte, fixed, override, try,
		case, float, params, typeof,
		catch, for, private, uint,
		char, foreach, protected, ulong,
		checked, goto, public, unchecked,
		class, if, readonly, unsafe,
		const, implicit, ref, ushort,
		continue, in, return, using,
		decimal, int, sbyte, virtual,
		default, interface, sealed, volatile,
		delegate, internal, short, void,
		do, is, sizeof, while,
		double, lock, stackalloc,
		else, long, static,
		enum, namespace, string},
	keywordstyle=\color{cyan},
	identifierstyle=\color{red},
}
\usepackage{caption}
\DeclareCaptionFont{black}{\color{black}}
\DeclareCaptionFormat{listing}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{%
	How Effective can an Adaptive AI Built With Predefined Expert Strategies be Against Competition Grade AI?} %\\
	%\large A Planning Approach to StarCraft AI}

%
%
% author name
\author{\IEEEauthorblockN{James Hellman\\}
\IEEEauthorblockA{Falmouth Games Academy\\
UK, Falmouth\\
Email: jh182233@falmouth.ac.uk\\}
}

% The paper headers -- please do not change these, but uncomment one of them as appropriate
% Uncomment this one for COMP320
\markboth{COMP320: Research Review and Proposal}{COMP320: Research Review and Proposal}
% Uncomment this one for COMP360
% \markboth{COMP360: Dissertation}{COMP360: Dissertation}

% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
Effective macro-management (the ability to create armies and expand bases), is essential to obtaining victory in Real-Time Strategy (RTS), in the research community many Artificial Intelligence's (AI's) have been created to handle this. One method is to use a design approach to create what is known as build orders, many of these build orders take from expert strategies used by real people in high ranking tournaments. Build orders can be ridged during games leaving little room for adaptation to the opponents strategy. In this paper a collection of build orders will be used to create an AI capable of interchanging these build orders to effectively counter several strategies. An assumption is made here that the AI will only be effective in the early stages of the game and will be outmanoeuvred in late-game stages. The effectiveness of this AI will be its time survived, and winning state.
\end{abstract}

\section{Introduction}
\IEEEPARstart{A}{rtificial} Intelligence can be defined as anything that gives the illusion of intelligence to an appropriate level \cite{AIBook}. In games AI has been used in both single and multi-player environments to help create a more immersive, challenging and fun experience. One such area which AI is prominent is in the RTS genre and since the call for more research to be made for AI in Real-Time Strategy (RTS) games by Michael Buro in 2004 \cite{CallFor}, research in this area has exploded, with hundreds of papers being written \cite{Survey}. This has given rise to the creation of many AI's in RTS games from AI's that are built with pre-defined build orders \cite{Swen} to deep Neural Networks \cite{Deep} that can learn from game-play, which will be covered in more detail later on in the paper.

RTS is a great test bed in AI research for its complex systems, involving many areas of interest from planning  Imperfect Information. \cite{StarCraftBot}

In RTS, strategy selection is perhaps the most important choice any player or AI can make, as this will dictate the actions and reactions which they take during playtime. Though a human player can be proficient at choosing their strategy, by simply scouting the map, finding the enemy and seeing what they are building. The human player can then counter accordingly, and if they countered incorrectly the human player can simply change their strategy to accommodate. Creating an AI to do the same though can be a huge and complex task \cite{Fuzzy}\cite{OnlineEvo}\cite{GoalDriven}, one way to achieve this result without a huge effort is to create a library of expert strategies, and having the AI select the appropriate one throughout the game. This can be achieved using tools such as Advanced Behaviour Oriented Design Environment (ABODE) and Parallel-rooted Ordered Slip-stack Hierarchical (POSH) reactive plans \cite{POSH}, which will also be covered later in the paper. These tools allow for an iterative design approach for AI's in games and in this paper will be focusing on the macro-management with a particular focus on build orders and the selection of strategies rather than micro-management. 

The method many papers use to create their AI is to use replays and train their AI to be able to counter strategies, this can be a slow process, so why not just program expert strategies into the AI and then the only thing the AI has to do is select one and follow it through, with some ability to jump between strategies at key points in-case a counter is detected. 



\section{StarCraft}
StarCraft the most popular RTS game of all time \cite{Current} is an RTS game developed by Blizzard Entertainment \cite{Blizzard}\cite{Release}, and released in 1998. Later that year StarCraft: Brood War was released and took hold in the e-sports community and is still popular today. StarCraft 2: Wings of Liberty was released much later in 2010, with most of the game mechanics the same other than balance changes, and the user interface (UI) were kept the same just with a visual overhaul. The premise of StarCraft is to gather resources, build a base, and build an army to then use to destroy an enemies base and army, during playtime there are also many upgrades available for these units to give them the edge over an enemy who did not spend the time acquiring them. There are many ways of doing this each player with a different order of building their armies/bases commonly referred to as their "Build Order" \cite{BuildOrder}. Build orders refer to a players macro-management, whereas in StarCraft Micro-management is a huge part of the game, as those with greater control over individual units can better outmanoeuvre their opponent, and thus defeat them. 

\section{Related Work}
In the StarCraft research community there are many different methods of AI creation. Some focus on micro-management like S. Liu et al \cite{EffectiveMicro} that uses a Genetic Algorithm (GA) and others that focus on macro-management looking at the build order like N. Justesen et al \cite{OnlineEvo}. Many of these research methods are cross depended and utilise more than one method for example, D. Churchill et al \cite{Agents} created the UAlbertaBot, which was intended to automate both build order planning and unit control. Though this paper is focusing on the planning aspect with an implementation of "either a Bayesian or other prediction algorithm" there are many other ways of creating an effective AI.

\subsection{Datasets}
A Dataset can be a collection of any data, for game AI a dataset can consist of thousands of replays with millions of game frames, and player actions\cite{Dataset}. This information can then put together to create a full game-state which allows for machine learning tasks \cite{Dataset17}. In AI research, datasets can be used in many approaches of development, one such use is to recreate game-states and evaluate them for prediction in realistic conditions \cite{SpecialTactics}.

 
\subsection{Bayesian Approaches}
Bayesian approaches are based on Bayes' Theorem, a calculation of probability or also known as a probabilistic model \cite{BayesianAI}. In papers by G. Synnaeve et al \cite{UnitsControl}\cite{SpecialTactics} they create an AI that controls units individually, they do this by using uncertainty which instead of asking where a unit might be, it makes rough estimations and acts upon that. Another use for the Bayesian approach is to predict strategies, by creating a probabilistic model that after learning from replays can predict an opponents strategy and adapt accordingly \cite{Bayesian}. A major downfalls of Bayesian Approaches is that it can be computationally intense to calculate.

\subsection{Micro-Management}
Micro management is a fundamental side of StarCraft game-play and many papers have their own approach to this aspect of RTS \cite{SOMA}\cite{EffectiveMicro}\cite{Swarm}\cite{MM}\cite{SpecialTactics}\cite{UnitsControl}. Many of these approaches us either Genetic Algorithms (GA) or Evolutionary Algorithms (EA) \cite{SOMA}\cite{EffectiveMicro}\cite{Swarm}, while others observe replays and apply a Monte-Carlo method to create data for practice use \cite{MM}. But most of these methods have one thing in common, they all use a version of machine learning \cite{Survey}.

\subsection{Prediction}
On a higher strategic level the prediction of the opponents strategy is an prominent approach used in research \cite{DataMine}\cite{Bayesian}\cite{Scouting}\cite{ReplayPred}. This type of research relies on the use of replays and machine learning to help the AI accurately predict a strategy, these do rely on the quantity and quality of replays used for the learning process\cite{DataMine}\cite{Bayesian}\cite{ReplayPred}. Another method for prediction is scouting alongside machine learning, this eliminates the need for replay observation and allows for a more real-time prediction \cite{Scouting}. Though this method does still require several games to be played before the AI can begin to have an accurate prediction.

\subsection{Full Game Play}
Many papers try to create an AI capable of handling all aspects of an RTS \cite{Agents}\cite{Hierarchical}\cite{HumanLevel}\cite{SCAIL}. These AI's tend to take several methods that have been created in other research and combining them to form a new AI \cite{Agents}. Another use for the full game play AI is to try and create a "Human-Like" AI, which can mimic the play-style of an expert human player though the current AI's are limited in this as players reported that the AI's used unusual unit movements or building placement \cite{EvalHuman}.

\subsection{Neural Networks}
Neural Networking are computational models loosely based on the functioning of biological brains \cite{Deep}. Given an input it computes an output by using a large number of neural units, in StarCraft it can be used to predict strategies or in the case of StarCraft 2 with its new architecture it can be used for full game-play. Using a neural network would be impractical for the purpose of this paper as ti would take many months to train.

\subsection{Planning}
Planning in StarCraft usually deals with the build order that the AI will use usually only dealing with macro-management. There are several different ways to use a build order, some will use a static build order that will not change throughout the game \cite{Swen}, and the more popular route is to allow the AI to jump between build orders during play-time, another term is Reactive Planning \cite{Fuzzy}\cite{OnlineEvo}\cite{GoalDriven}. there has been some work on creating the build orders on the fly by finding out that most optimal method of gathering resource and building units \cite{BuildOrder}. Planning is perhaps the most optimal approach to creating an AI as there is little real-time calculations to make. Through the use of POSH tools \cite{POSH}, you can iteratively design AI prototypes and deploy quickly \cite{Swen}. Though many other papers focus on their micro-management abilities they lack the greater control of the game, the ability to macro-management. This lack of large scale control is usually due to the heavy computational requirements of controlling each individual component of the game. This is where 

\subsection{Competition Grade AI}
In the StarCraft AI community there are many AI's that have been created to compete against each other, and in this paper a competition grade AI is defined as an AI that has been entered to the AI for Interactive Digital Entertainment conference (AAIDE) StarCraft AI Competition. A yearly competition hosted by David Churchill and sponsored by AIIDE. AI's of this grade include:
\begin{itemize}
	\item ZZZKBot Winner of the 2017 AIIDE StarCraft AI Competition \cite{ZZZK}
	\item Iron Winner of the 2016 AIIDE StarCraft AI Competition \cite{Iron}
	\item UAlbertaBot Winner of the 2013/2011 AIIDE StarCraft AI Competition \cite{UAlbertaBotBot}
	\item Skynet Winner of the 2012 AIIDE StarCraft AI Competition \cite{Skynet}
\end{itemize}

These AI's use several strategies along with different factions, and were chosen as they have all previously won the AIIDE StarCraft AI competition \cite{Results}.

\section{Method and Motivation}
This paper will be focusing on the implementation of an AI with pre-built build orders and their counters taken from Liquipedia \cite{Liquid}, a website dedicated to StarCraft, on the there they have a collection of strategies that are free to use in any capacity. Building upon these build orders the experiment will also include a method for swapping between the orders at any point, to know when to do this, the AI will scout the map in search of the opponent and compare their current building to its stored build orders and find an appropriate counter. The issue with this method is that in late game the AI will struggle to decide which build order to continue. 

Research into AI in any form is valuable as it provides a greater understanding on how AI can work and could contribute to more complex systems by providing a foundation for others to build upon. The hope here is that this form of planning and strategy selection could be applied to future game AI's.

\subsection{Tools}
There are several tools that will be using in this experiment, these include The Brood War Application Programming Interface (BWAPI), POSH tools, specifically POSH Sharp which is an interface that uses cSharp instead of C++, and the ABODE editing software which uses POSH plans to create Behaviour Oriented Design's for AI's. 

BWAPI \cite{BWAPI} is a open source software that creates an interface for a custom AI to use to communicate with the game. BWAPI deliberately does not give access to all the games information \cite{POSH}, limiting the AI to only be able to have information on the enemy if there is no Fog-of-War currently covering them, as well as the size of the map and base locations. This prevents custom AI's from cheating and ensures a fair game, though this could be considered a plus as it means that the developers of these AI's do not need to worry about using information that could cause their AI to cheat. Though this does mean hat all the AI's must work in an imperfect environment which forces the AI to have to scout for information.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.5\textwidth]{POSH}
	\caption{POSH plan for the Three Hatch Hydra build plan inside the ABODE editor.}
	\label{Fig1}
\end{figure}

The POSH plan in the ABODE Environment as seen in Figure 1, is a visual planning tool that allows for hierarchy of actions with associated triggers. 

\begin{lstlisting}
[ExecutableAction("SelectExtractorLocation")]
public bool SelectExtractorLocation()
{
    // enough resources available?
    if (!CanMorphUnit(bwapi.UnitTypes_Zerg_Extractor) || !Interface().baseLocations.ContainsKey((int)Interface().currentBuildSite))
    return false;
    
    TilePosition buildPosition = Interface().baseLocations[(int)Interface().currentBuildSite];
    // are there any geysers available/visible?
    IEnumerable<Unit> geysers = Interface()
        .GetGeysers().Where(geyser => geyser.getResources() > 0);
    if (geysers.Count() < 1)
        return false;


    // sort by closest path for ground units from selected build base
    TilePosition closest = geysers
        .OrderBy(geyser => geyser.getDistance(new Position(buildPosition)))
        .First().getTilePosition();

    // if there is a close geyers we are done
    if (closest is TilePosition)
    {
        this.buildLocation = closest;
        builder = Interface().GetBuilder(buildPosition);
        //move(new Position(closest), builder);
        // if (builder.getDistance(new Position(closest)) < DELTADISTANCE)
        //     return true;
        return true;
    }
    return false;
}
\end{lstlisting}
\begin{figure}[h]
	\centering
	\caption{cSharp behaviour code snippet for selecting an extractor location for the Zerg.}
	\label{Fig2}
\end{figure}

\subsection{Hypothesis}

To create a StarCraft AI you need to first have in mind what it needs to do, in the case of this paper the AI needs to 

\subsection{Metrics}
In this paper the StarCraft AI will be measured on its success using two factors in order of importance:
\begin{itemize}
	\item[] \centering Time Survived
	\item[] End game Condition
\end{itemize}

Through these factors the effectiveness of the AI can be determined, as the average time of a StarCraft game can last between 10-20 minutes if the AI survives pas the upper limit of this time or wins the game it will support a greater effectiveness. Though if the AI does not survive past the lower limit of that time or looses it will negate the effectiveness. To begin with the AI will be pitted against the inbuilt AI as a test-bed, if it should have a high effectiveness it will then be put against an open source competition grade AI, and measured from there.


% references section

\bibliographystyle{IEEEtran}
\bibliography{references}

% Appendices


% that's all folks
\end{document}
